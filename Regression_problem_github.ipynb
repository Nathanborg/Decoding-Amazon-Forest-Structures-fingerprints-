{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3vK-yJF8ES9"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, UpSampling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load data\n",
        "path = '/content/trainingfinal5'\n",
        "class_dirs = sorted([d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))])[0:18]\n",
        "\n",
        "# Create temporary directory for test folders\n",
        "temp_path = os.path.join(path, 'temp')\n",
        "os.makedirs(temp_path, exist_ok=True)\n",
        "\n",
        "def create_autoencoder():\n",
        "    autoencoder = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(64,64, 3)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D((2, 2), padding='same'),\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D((2, 2), padding='same'),\n",
        "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        UpSampling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        UpSampling2D((2, 2)),\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        UpSampling2D((2, 2)),\n",
        "        Conv2D(3, (3, 3), activation='sigmoid', padding='same')\n",
        "    ])\n",
        "    return autoencoder\n",
        "\n",
        "# Train PLS regressor\n",
        "def create_pls_regressor():\n",
        "    regressor = PLSRegression(n_components=15)  # Adjust the number of components based on your needs\n",
        "    return regressor\n",
        "\n",
        "# Load data\n",
        "for test_dir in class_dirs:\n",
        "    # Load images and labels for training and testing\n",
        "    X_train, y_train = [], []\n",
        "    X_test, y_test = [], []\n",
        "\n",
        "    print(f\"\\nTesting on directory: {test_dir}\")\n",
        "    print(\"Training on directories: \", [d for d in class_dirs if d != test_dir])\n",
        "\n",
        "    for class_dir in class_dirs:\n",
        "        class_path = os.path.join(path, class_dir)\n",
        "        label = float(class_dir.split(\"_\")[1])\n",
        "\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "\n",
        "        for img_file in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, img_file)\n",
        "            img = tf.keras.preprocessing.image.load_img(img_path, target_size=(64, 64))\n",
        "            img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "            if class_dir == test_dir:\n",
        "                X_test.append(img_array)\n",
        "                y_test.append(label)\n",
        "            else:\n",
        "                X_train.append(img_array)\n",
        "                y_train.append(label)\n",
        "\n",
        "    # Move test folder to temporary directory\n",
        "    src_dir = os.path.join(path, test_dir)\n",
        "    dst_dir = os.path.join(temp_path, test_dir)\n",
        "    shutil.move(src_dir, dst_dir)\n",
        "\n",
        "    X_train = np.array(X_train) / 255.0\n",
        "    y_train = np.array(y_train)\n",
        "    X_test = np.array(X_test) / 255.0\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "    # Train autoencoder\n",
        "    autoencoder = create_autoencoder()\n",
        "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "    autoencoder.fit(X_train, X_train, epochs=15, shuffle=True, validation_split=0.01)\n",
        "\n",
        "    # Extract the trained encoder part of the autoencoder\n",
        "    encoder_input = autoencoder.layers[0].input\n",
        "    encoder_output = autoencoder.layers[4].output\n",
        "    encoder = Model(inputs=encoder_input, outputs=encoder_output)\n",
        "\n",
        "    X_train_encoded = encoder.predict(X_train)\n",
        "    X_train_encoded = X_train_encoded.reshape(X_train_encoded.shape[0], -1)\n",
        "\n",
        "    # Encode testing data\n",
        "    X_test_encoded = encoder.predict(X_test)\n",
        "    X_test_encoded = X_test_encoded.reshape(X_test_encoded.shape[0], -1)\n",
        "\n",
        "    # Scale the data\n",
        "    scaler = StandardScaler()\n",
        "    X_train_encoded_scaled = scaler.fit_transform(X_train_encoded)\n",
        "    X_test_encoded_scaled = scaler.transform(X_test_encoded)\n",
        "\n",
        "    # Train PLS regressor\n",
        "    pls_regressor = create_pls_regressor()\n",
        "    pls_regressor.fit(X_train_encoded, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    preds = pls_regressor.predict(X_test_encoded).ravel()\n",
        "\n",
        "    # Save the predictions for this folder\n",
        "    with open(f\"predictions_auto_final_ala222{test_dir}.txt\", \"w\") as f:\n",
        "        for pred, true_label in zip(preds, y_test):\n",
        "            f.write(f\"True label: {true_label}, Predicted value: {pred}\\n\")\n",
        "\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    # Move test folder back to the original directory\n",
        "    shutil.move(dst_dir, src_dir)\n"
      ]
    }
  ]
}